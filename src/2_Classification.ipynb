{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-24T20:09:55.817220Z",
     "end_time": "2023-04-24T20:09:56.541972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2id: {'Negative': 0, 'Positive': 1}; id2word: {0: 'Negative', 1: 'Positive'}\n",
      "{'label': 1, 'target_text': 'the most wonderful part of the trip', 'text': 'Yes , it really was a great experience and we visited various places but the most wonderful part of the trip was our stay at the Oberoi Udaivilas Luxury Hotel .'}\n",
      "{'label': 1, 'target_text': 'how grand looks', 'text': 'I can ’t explain in words how grand this place looks .'}\n",
      "{'label': 1, 'target_text': 'unique blend of the old world royal charm and the modern luxuries', 'text': 'It is a unique blend of the old world royal charm and the modern luxuries .'}\n",
      "{'label': 1, 'target_text': 'definitely going again', 'text': 'I ’m definitely going there again whenever I get a chance .'}\n",
      "{'label': 0, 'target_text': 'Bit pricey', 'text': 'Bit pricey and but away from center'}\n",
      "{'label': 0, 'target_text': 'away from center', 'text': 'Bit pricey and but away from center'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "from paddlenlp.metrics import AccuracyAndF1\n",
    "from paddlenlp.datasets import load_dataset\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp.transformers import SkepTokenizer, SkepModel, LinearDecayWithWarmup\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "def read_json(data_path):\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        for sample in data:\n",
    "            text = sample[\"text\"]\n",
    "            for opinion in sample['opinions']:\n",
    "                polar_expression = \" \".join(opinion['Polar_expression'][0])\n",
    "                label = label2id[opinion[\"Polarity\"]]\n",
    "                example = {\"label\": int(label), \"target_text\": polar_expression, \"text\": text}\n",
    "                yield example\n",
    "\n",
    "def load_dict(dict_path):\n",
    "    with open(dict_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        words = [word.strip() for word in f.readlines()]\n",
    "        word2id = dict(zip(words, range(len(words))))\n",
    "        id2word = dict((v, k) for k, v in word2id.items())\n",
    "        print(f\"word2id: {word2id}; id2word: {id2word}\")\n",
    "        return word2id, id2word\n",
    "\n",
    "train_path = \"./data/opener_en_raw/train.json\"\n",
    "dev_path = \"./data/opener_en_raw/dev.json\"\n",
    "test_path = \"./data/opener_en_raw/test.json\"\n",
    "label_path = \"./data/opener_en_relations/label.dict\"\n",
    "\n",
    "# load and process data\n",
    "label2id, id2label = load_dict(label_path)\n",
    "train_ds = load_dataset(read_json, data_path=train_path, lazy=False)\n",
    "dev_ds =  load_dataset(read_json, data_path=dev_path, lazy=False)\n",
    "test_ds =  load_dataset(read_json, data_path=test_path, lazy=False)\n",
    "\n",
    "# print examples\n",
    "for example in train_ds[:6]:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-04-24 19:39:56,460] [    INFO]\u001B[0m - Found /home/christophe/.paddlenlp/models/skep_ernie_2.0_large_en/skep_ernie_2.0_large_en.vocab.txt\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:  [101, 1996, 2087, 6919, 2112, 1997, 1996, 4440, 102, 2748, 1010, 2009, 2428, 2001, 1037, 2307, 3325, 1998, 2057, 4716, 2536, 3182, 2021, 1996, 2087, 6919, 2112, 1997, 1996, 4440, 2001, 2256, 2994, 2012, 1996, 15578, 26692, 20904, 4886, 14762, 3022, 9542, 3309, 1012, 102]\n",
      "token_type_ids:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "seq_len:  45\n",
      "label:  1\n",
      "\n",
      "input_ids:  [101, 2129, 2882, 3504, 102, 1045, 2064, 1521, 1056, 4863, 1999, 2616, 2129, 2882, 2023, 2173, 3504, 1012, 102]\n",
      "token_type_ids:  [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "seq_len:  19\n",
      "label:  1\n",
      "\n",
      "input_ids:  [101, 4310, 12586, 1997, 1996, 2214, 2088, 2548, 11084, 1998, 1996, 2715, 28359, 9496, 2229, 102, 2009, 2003, 1037, 4310, 12586, 1997, 1996, 2214, 2088, 2548, 11084, 1998, 1996, 2715, 28359, 9496, 2229, 1012, 102]\n",
      "token_type_ids:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "seq_len:  35\n",
      "label:  1\n",
      "\n",
      "input_ids:  [101, 5791, 2183, 2153, 102, 1045, 1521, 1049, 5791, 2183, 2045, 2153, 7188, 1045, 2131, 1037, 3382, 1012, 102]\n",
      "token_type_ids:  [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "seq_len:  19\n",
      "label:  1\n",
      "\n",
      "input_ids:  [101, 2978, 3976, 2100, 102, 2978, 3976, 2100, 1998, 2021, 2185, 2013, 2415, 102]\n",
      "token_type_ids:  [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "seq_len:  14\n",
      "label:  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def convert_example_to_feature(example, tokenizer, label2id, max_seq_len=512, is_test=False):\n",
    "    encoded_inputs = tokenizer(example[\"target_text\"], text_pair=example[\"text\"], max_seq_len=max_seq_len,\n",
    "                               return_length=True)\n",
    "\n",
    "    if not is_test:\n",
    "        label = example[\"label\"]\n",
    "        return encoded_inputs[\"input_ids\"], encoded_inputs[\"token_type_ids\"], encoded_inputs[\"seq_len\"], label\n",
    "\n",
    "    return encoded_inputs[\"input_ids\"], encoded_inputs[\"token_type_ids\"], encoded_inputs[\"seq_len\"]\n",
    "\n",
    "\n",
    "model_name = \"skep_ernie_2.0_large_en\"\n",
    "batch_size = 8\n",
    "max_seq_len = 512\n",
    "\n",
    "tokenizer = SkepTokenizer.from_pretrained(model_name)\n",
    "trans_func = partial(convert_example_to_feature, tokenizer=tokenizer, label2id=label2id, max_seq_len=max_seq_len)\n",
    "train_ds = train_ds.map(trans_func, lazy=False)\n",
    "dev_ds = dev_ds.map(trans_func, lazy=False)\n",
    "test_ds = test_ds.map(trans_func, lazy=False)\n",
    "\n",
    "# print examples\n",
    "# print examples\n",
    "for example in train_ds[:5]:\n",
    "    print(\"input_ids: \", example[0])\n",
    "    print(\"token_type_ids: \", example[1])\n",
    "    print(\"seq_len: \", example[2])\n",
    "    print(\"label: \", example[3])\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T19:39:56.461685Z",
     "end_time": "2023-04-24T19:39:57.154276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-04-24 19:40:01,532] [    INFO]\u001B[0m - Already cached /home/christophe/.paddlenlp/models/skep_ernie_2.0_large_en/skep_ernie_2.0_large_en.pdparams\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0424 19:40:01.534180 41826 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 12.1, Runtime API Version: 11.7\n",
      "W0424 19:40:01.536700 41826 gpu_resources.cc:91] device: 0, cuDNN Version: 8.8.\n"
     ]
    }
   ],
   "source": [
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\n",
    "    Stack(dtype=\"int64\"),\n",
    "    Stack(dtype=\"int64\")\n",
    "): fn(samples)\n",
    "\n",
    "train_batch_sampler = paddle.io.BatchSampler(train_ds, batch_size=batch_size, shuffle=True)\n",
    "dev_batch_sampler = paddle.io.BatchSampler(dev_ds, batch_size=batch_size, shuffle=False)\n",
    "test_batch_sampler = paddle.io.BatchSampler(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loader = paddle.io.DataLoader(train_ds, batch_sampler=train_batch_sampler, collate_fn=batchify_fn)\n",
    "dev_loader = paddle.io.DataLoader(dev_ds, batch_sampler=dev_batch_sampler, collate_fn=batchify_fn)\n",
    "test_loader = paddle.io.DataLoader(test_ds, batch_sampler=test_batch_sampler, collate_fn=batchify_fn)\n",
    "\n",
    "\n",
    "class SkepForSequenceClassification(paddle.nn.Layer):\n",
    "    def __init__(self, skep, num_classes=2, dropout=None):\n",
    "        super(SkepForSequenceClassification, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.skep = skep\n",
    "        self.dropout = paddle.nn.Dropout(dropout if dropout is not None else self.skep.config[\"hidden_dropout_prob\"])\n",
    "        self.classifier = paddle.nn.Linear(self.skep.config[\"hidden_size\"], num_classes)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "        _, pooled_output = self.skep(input_ids, token_type_ids=token_type_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "def set_seed(seed):\n",
    "    paddle.seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# model hyperparameter  setting\n",
    "num_epoch = 3\n",
    "learning_rate = 3e-5\n",
    "weight_decay = 0.01\n",
    "warmup_proportion = 0.1\n",
    "max_grad_norm = 1.0\n",
    "log_step = 20\n",
    "eval_step = 100\n",
    "seed = 1000\n",
    "checkpoint = \"./checkpoint/\"\n",
    "\n",
    "set_seed(seed)\n",
    "use_gpu = True if paddle.get_device().startswith(\"gpu\") else False\n",
    "print('use_gpu: ', use_gpu)\n",
    "if use_gpu:\n",
    "    paddle.set_device(\"gpu:0\")\n",
    "if not os.path.exists(checkpoint):\n",
    "    os.mkdir(checkpoint)\n",
    "\n",
    "skep = SkepModel.from_pretrained(model_name)\n",
    "model = SkepForSequenceClassification(skep, num_classes=len(label2id))\n",
    "\n",
    "num_training_steps = len(train_loader) * num_epoch\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate=learning_rate, total_steps=num_training_steps, warmup=warmup_proportion)\n",
    "decay_params = [p.name for n, p in model.named_parameters() if not any(nd in n for nd in [\"bias\", \"norm\"])]\n",
    "grad_clip = paddle.nn.ClipGradByGlobalNorm(max_grad_norm)\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=lr_scheduler, parameters=model.parameters(), weight_decay=weight_decay, apply_decay_param_fun=lambda x: x in decay_params, grad_clip=grad_clip)\n",
    "\n",
    "metric = AccuracyAndF1()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T19:40:01.533092Z",
     "end_time": "2023-04-24T19:40:05.612098Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 - global_step: 20/1083 - loss:0.818317\n",
      "epoch: 1 - global_step: 40/1083 - loss:0.390278\n",
      "epoch: 1 - global_step: 60/1083 - loss:0.355876\n",
      "epoch: 1 - global_step: 80/1083 - loss:0.119800\n",
      "epoch: 1 - global_step: 100/1083 - loss:0.001870\n",
      "best F1 performence has been updated: 0.00000 --> 0.95470\n",
      "evalution result: accuracy:0.93500 precision: 0.94483, recall: 0.96479,  F1: 0.95470\n",
      "epoch: 1 - global_step: 120/1083 - loss:0.017386\n",
      "epoch: 1 - global_step: 140/1083 - loss:0.477388\n",
      "epoch: 1 - global_step: 160/1083 - loss:0.800743\n",
      "epoch: 1 - global_step: 180/1083 - loss:0.004216\n",
      "epoch: 1 - global_step: 200/1083 - loss:0.612047\n",
      "evalution result: accuracy:0.93000 precision: 0.93243, recall: 0.97183,  F1: 0.95172\n",
      "epoch: 1 - global_step: 220/1083 - loss:0.001192\n",
      "epoch: 1 - global_step: 240/1083 - loss:0.035013\n",
      "epoch: 1 - global_step: 260/1083 - loss:0.126476\n",
      "epoch: 1 - global_step: 280/1083 - loss:0.006750\n",
      "epoch: 1 - global_step: 300/1083 - loss:0.000322\n",
      "evalution result: accuracy:0.93250 precision: 0.97770, recall: 0.92606,  F1: 0.95118\n",
      "epoch: 1 - global_step: 320/1083 - loss:0.009158\n",
      "epoch: 1 - global_step: 340/1083 - loss:0.009025\n",
      "epoch: 1 - global_step: 360/1083 - loss:0.005275\n",
      "epoch: 2 - global_step: 380/1083 - loss:0.002269\n",
      "epoch: 2 - global_step: 400/1083 - loss:0.007273\n",
      "best F1 performence has been updated: 0.95470 --> 0.95871\n",
      "evalution result: accuracy:0.94250 precision: 0.97802, recall: 0.94014,  F1: 0.95871\n",
      "epoch: 2 - global_step: 420/1083 - loss:0.039378\n",
      "epoch: 2 - global_step: 440/1083 - loss:0.284419\n",
      "epoch: 2 - global_step: 460/1083 - loss:0.000547\n",
      "epoch: 2 - global_step: 480/1083 - loss:0.001911\n",
      "epoch: 2 - global_step: 500/1083 - loss:0.001809\n",
      "best F1 performence has been updated: 0.95871 --> 0.96466\n",
      "evalution result: accuracy:0.95000 precision: 0.96809, recall: 0.96127,  F1: 0.96466\n",
      "epoch: 2 - global_step: 520/1083 - loss:0.001695\n",
      "epoch: 2 - global_step: 540/1083 - loss:0.001354\n",
      "epoch: 2 - global_step: 560/1083 - loss:1.402315\n",
      "epoch: 2 - global_step: 580/1083 - loss:0.002944\n",
      "epoch: 2 - global_step: 600/1083 - loss:0.024482\n",
      "best F1 performence has been updated: 0.96466 --> 0.97193\n",
      "evalution result: accuracy:0.96000 precision: 0.96853, recall: 0.97535,  F1: 0.97193\n",
      "epoch: 2 - global_step: 620/1083 - loss:0.280505\n",
      "epoch: 2 - global_step: 640/1083 - loss:0.000370\n",
      "epoch: 2 - global_step: 660/1083 - loss:0.001690\n",
      "epoch: 2 - global_step: 680/1083 - loss:0.540056\n",
      "epoch: 2 - global_step: 700/1083 - loss:0.005098\n",
      "evalution result: accuracy:0.95500 precision: 0.97500, recall: 0.96127,  F1: 0.96809\n",
      "epoch: 2 - global_step: 720/1083 - loss:0.000352\n",
      "epoch: 3 - global_step: 740/1083 - loss:0.487078\n",
      "epoch: 3 - global_step: 760/1083 - loss:0.009248\n",
      "epoch: 3 - global_step: 780/1083 - loss:0.000252\n",
      "epoch: 3 - global_step: 800/1083 - loss:0.001395\n",
      "evalution result: accuracy:0.94750 precision: 0.96466, recall: 0.96127,  F1: 0.96296\n",
      "epoch: 3 - global_step: 820/1083 - loss:0.003026\n",
      "epoch: 3 - global_step: 840/1083 - loss:0.000408\n",
      "epoch: 3 - global_step: 860/1083 - loss:0.000357\n",
      "epoch: 3 - global_step: 880/1083 - loss:0.000763\n",
      "epoch: 3 - global_step: 900/1083 - loss:0.000325\n",
      "best F1 performence has been updated: 0.97193 --> 0.97535\n",
      "evalution result: accuracy:0.96500 precision: 0.97535, recall: 0.97535,  F1: 0.97535\n",
      "epoch: 3 - global_step: 920/1083 - loss:0.000376\n",
      "epoch: 3 - global_step: 940/1083 - loss:0.000259\n",
      "epoch: 3 - global_step: 960/1083 - loss:0.000241\n",
      "epoch: 3 - global_step: 980/1083 - loss:0.512828\n",
      "epoch: 3 - global_step: 1000/1083 - loss:0.000237\n",
      "best F1 performence has been updated: 0.97535 --> 0.97544\n",
      "evalution result: accuracy:0.96500 precision: 0.97203, recall: 0.97887,  F1: 0.97544\n",
      "epoch: 3 - global_step: 1020/1083 - loss:0.274039\n",
      "epoch: 3 - global_step: 1040/1083 - loss:0.000669\n",
      "epoch: 3 - global_step: 1060/1083 - loss:0.000654\n",
      "epoch: 3 - global_step: 1080/1083 - loss:0.000591\n",
      "evalution result: accuracy:0.96250 precision: 0.97193, recall: 0.97535,  F1: 0.97364\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, data_loader, metric):\n",
    "\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    for batch_data in data_loader:\n",
    "        input_ids, token_type_ids, _, labels = batch_data\n",
    "        logits = model(input_ids, token_type_ids=token_type_ids)\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "\n",
    "    accuracy, precision, recall, f1, _ = metric.accumulate()\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def train():\n",
    "    # start to train model\n",
    "    global_step, best_f1 = 1, 0.\n",
    "    model.train()\n",
    "    for epoch in range(1, num_epoch+1):\n",
    "        for batch_data in train_loader():\n",
    "            input_ids, token_type_ids, _, labels = batch_data\n",
    "            # logits: batch_size, seql_len, num_tags\n",
    "            logits = model(input_ids, token_type_ids=token_type_ids)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "            if global_step > 0 and global_step % log_step == 0:\n",
    "                print(f\"epoch: {epoch} - global_step: {global_step}/{num_training_steps} - loss:{loss.numpy().item():.6f}\")\n",
    "            if (global_step > 0 and global_step % eval_step == 0) or global_step == num_training_steps:\n",
    "                accuracy, precision, recall, f1  = evaluate(model, dev_loader,  metric)\n",
    "                model.train()\n",
    "                if f1 > best_f1:\n",
    "                    print(f\"best F1 performence has been updated: {best_f1:.5f} --> {f1:.5f}\")\n",
    "                    best_f1 = f1\n",
    "                    paddle.save(model.state_dict(), f\"{checkpoint}/best_cls.pdparams\")\n",
    "                print(f'evalution result: accuracy:{accuracy:.5f} precision: {precision:.5f}, recall: {recall:.5f},  F1: {f1:.5f}')\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "    paddle.save(model.state_dict(), f\"{checkpoint}/final_cls.pdparams\")\n",
    "\n",
    "train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T19:40:30.701851Z",
     "end_time": "2023-04-24T19:42:13.492777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[2023-04-24 19:42:13,882] [    INFO]\u001B[0m - Already cached /home/christophe/.paddlenlp/models/skep_ernie_2.0_large_en/skep_ernie_2.0_large_en.pdparams\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evalution result: accuracy:0.96647 precision: 0.98296, recall: 0.96812,  F1: 0.97549\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model_path = \"./checkpoint/best_cls.pdparams\"\n",
    "\n",
    "loaded_state_dict = paddle.load(model_path)\n",
    "skep = SkepModel.from_pretrained(model_name)\n",
    "model = SkepForSequenceClassification(skep, num_classes=len(label2id))\n",
    "model.load_dict(loaded_state_dict)\n",
    "\n",
    "accuracy, precision, recall, f1  = evaluate(model, test_loader,  metric)\n",
    "print(f'evalution result: accuracy:{accuracy:.5f} precision: {precision:.5f}, recall: {recall:.5f},  F1: {f1:.5f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T19:42:13.494600Z",
     "end_time": "2023-04-24T19:42:16.420314Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
